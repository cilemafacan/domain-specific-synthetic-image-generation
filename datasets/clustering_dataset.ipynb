{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import openslide as ops\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WSIS_DIR = \"../../../Lfstorage/wsis_2/\"\n",
    "NUM_CLUSTERS = 4\n",
    "embed_dataset = os.listdir('./embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_embeddings(embeddings, n_clusters):\n",
    "    all_embeddings = np.concatenate([data['embedding_vector'] for data in embeddings], axis=0)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(all_embeddings)\n",
    "    labels = kmeans.labels_\n",
    "    for i, data in enumerate(embeddings):\n",
    "        data[\"label\"] = labels[i]\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_slide(slide_path, slide_name):\n",
    "    for root, dirs, files in os.walk(slide_path):\n",
    "        for file in files:\n",
    "            if slide_name in file:\n",
    "                path = os.path.join(root, file)\n",
    "                organ = root.split('/')[-1]\n",
    "                return path, organ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patches(num_patches_per_cluster, dataset, title):\n",
    "    unique_labels = set([data['label'] for data in dataset])\n",
    "    num_labels = len(unique_labels)\n",
    "\n",
    "    selected_data = []\n",
    "    for label in unique_labels:\n",
    "        data = [data for data in dataset if data['label'] == label]\n",
    "        random.shuffle(data)\n",
    "        selected_data.extend(data[:num_patches_per_cluster])\n",
    "\n",
    "    print(\"Number of selected patches: \", len(selected_data))\n",
    "\n",
    "    num_labels = len(unique_labels)\n",
    "    fig, axs = plt.subplots(num_labels, num_patches_per_cluster, figsize=(20, 8), dpi=200)\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    for i, data in enumerate(selected_data):\n",
    "        title = f\"Label: {data['label']}\\n {data['slide_name']}_{data['x']}_{data['y']}\"\n",
    "        axs[i // num_patches_per_cluster, i % num_patches_per_cluster].set_title(title).set_size(8)\n",
    "\n",
    "        slide_path,_ = search_slide(WSIS_DIR, data['slide_name'])\n",
    "        region = (data['x'], data['y'])\n",
    "        size = data[\"patch_size\"]\n",
    "        resize = data[\"resize\"]\n",
    "        patch_image = ops.open_slide(slide_path).read_region(region, 0, size).convert(\"RGB\").resize(resize)\n",
    "        axs[i // num_patches_per_cluster, i % num_patches_per_cluster].imshow(patch_image)\n",
    "        axs[i // num_patches_per_cluster, i % num_patches_per_cluster] \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    labels = [data['label'] for data in dataset]\n",
    "    counter = Counter(labels)\n",
    "    print(counter)\n",
    "    print(\"-\" * 50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_selected_patches(embeddings, num_patches, title):\n",
    "    fig, axs = plt.subplots(1, num_patches, figsize=(20, 3), dpi=200)\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    random.shuffle(embeddings)\n",
    "\n",
    "    for i, data in enumerate(embeddings[:num_patches]):\n",
    "        title = f\"Label: {data['label']}\\n {data['slide_name']}_{data['x']}_{data['y']}\"\n",
    "        axs[i].set_title(title).set_size(8)\n",
    "        slide_path,_ = search_slide(WSIS_DIR, data['slide_name'])\n",
    "        region = (data['x'], data['y'])\n",
    "        size = data[\"patch_size\"]\n",
    "        resize = data[\"resize\"]\n",
    "        patch_image = ops.open_slide(slide_path).read_region(region, 0, size).convert(\"RGB\").resize(resize)\n",
    "        axs[i].imshow(patch_image)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_patches(dataset, label_id, embeddings_name):\n",
    "    selected_data = [data for data in dataset if data['label'] == label_id]\n",
    "    s = []\n",
    "    for data in selected_data:\n",
    "        slide_path, organ = search_slide(WSIS_DIR, data['slide_name'])\n",
    "        data['organ'] = organ\n",
    "        s.append(data)\n",
    "    pickle.dump(s, open(f\"./selected_embeddings/selected_{label_id}_{embeddings_name}\", \"wb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./clustered_embeddings'):\n",
    "    os.makedirs('./clustered_embeddings')\n",
    "\n",
    "for embeddings_name in embed_dataset:\n",
    "    dataset = pickle.load(open(f'./embeddings/{embeddings_name}', 'rb'))\n",
    "    all_embeddings = np.concatenate([data['embedding_vector'] for data in dataset], axis=0)\n",
    "    print(\"Embeddings: \", embeddings_name)\n",
    "    print(\"Shape of embeddings: \", all_embeddings.shape)\n",
    "\n",
    "    clustered_embeddings = cluster_embeddings(dataset, NUM_CLUSTERS)\n",
    "    plot_patches(num_patches_per_cluster=10, dataset=clustered_embeddings, title=embeddings_name)\n",
    "    pickle.dump(clustered_embeddings, open(f\"./clustered_embeddings/clustered_{embeddings_name}\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./selected_embeddings'):\n",
    "    os.makedirs('./selected_embeddings')\n",
    "\n",
    "label_ids = [[2]]\n",
    "for i,embeddings_name in enumerate(embed_dataset):\n",
    "    dataset = pickle.load(open(f'./clustered_embeddings/clustered_{embeddings_name}', 'rb'))\n",
    "    for label in label_ids[i]:\n",
    "        select_patches(dataset, label, embeddings_name)\n",
    "        print(f\"Selected patches for {embeddings_name} saved successfully.\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dataset = os.listdir('./selected_embeddings')\n",
    "\n",
    "for selected_embeddings_name in selected_dataset:\n",
    "    dataset = pickle.load(open(f'./selected_embeddings/{selected_embeddings_name}', 'rb'))\n",
    "    \n",
    "    print(\"Length of selected dataset: \", len(dataset))\n",
    "    plot_selected_patches(dataset, num_patches=10, title=selected_embeddings_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = []\n",
    "\n",
    "for selected_embeddings_name in selected_dataset:\n",
    "    dataset = pickle.load(open(f'./selected_embeddings/{selected_embeddings_name}', 'rb'))\n",
    "    \n",
    "    merged_dataset.extend(dataset)\n",
    "\n",
    "if not os.path.exists('./merged_embeddings'):\n",
    "    os.makedirs('./merged_embeddings')\n",
    "\n",
    "num_of_organs = Counter([data['organ'] for data in merged_dataset])\n",
    "print(num_of_organs)\n",
    "pickle.dump(merged_dataset, open(f\"./merged_embeddings/merged_dataset.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Merged dataset saved successfully.\")\n",
    "print(\"Merged dataset size: \", len(merged_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "path",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
