{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from utils.dataset_loader import CustomDatasetFromSlide\n",
    "from utils.latent_extractor import ImageEmbeddingExtractor, TextEmbeddingExtractor\n",
    "from datasets import load_dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"T2I\"\n",
    "device = \"cuda:2\"\n",
    "\n",
    "if MODE == \"T2I\":\n",
    "    text_encoder_base_name = \"openai/clip-vit-large-patch14\"\n",
    "    model_name = \"../trained_models/histopathology-diffusion-t2i-256\"\n",
    "    text_embedding_extractor = TextEmbeddingExtractor(text_encoder_name=text_encoder_base_name, device=device)\n",
    "\n",
    "elif MODE == \"E2I\":\n",
    "    model_name = \"../trained_models/histopathology-diffusion-e2i-256\"\n",
    "\n",
    "else:\n",
    "    image_encoder_base_name = \"openai/clip-vit-large-patch14\"\n",
    "    model_name = \"../trained_models/histopathology-diffusion-i2i-256\"\n",
    "    image_embedding_extractor = ImageEmbeddingExtractor(img_encoder_name=image_encoder_base_name, device=device)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Cilem/mixed-histopathology-512\"\n",
    "dataset = load_dataset(dataset_name)\n",
    "slide_dir = \"/home/cilem/Lfstorage/wsis\"\n",
    "\n",
    "\n",
    "dataset = CustomDatasetFromSlide(dataset, slide_dir=slide_dir, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = StableDiffusionPipeline.from_pretrained(model_name, safety_checker=None)\n",
    "pipeline = pipeline.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n",
    "for data in data_loader:\n",
    "\n",
    "    image = data[\"image\"]\n",
    "    google_embedding_vector = data[\"embedding\"]\n",
    "    organ = data[\"organ\"]\n",
    "\n",
    "    if MODE == \"T2I\":\n",
    "        text = [f\"histopathology image of {organ[j]}\" for j in range(len(organ))]\n",
    "        embedding = text_embedding_extractor.extract_text_embedding(text=text)\n",
    "        embedding = torch.from_numpy(embedding).to(device)\n",
    "    \n",
    "    elif MODE == \"E2I\":\n",
    "        embedding = google_embedding_vector\n",
    "        \n",
    "    else:\n",
    "        embedding = image_embedding_extractor.extract_image_embedding(image=image)\n",
    "        embedding = torch.from_numpy(embedding).to(device)\n",
    "        embedding = embedding.unsqueeze(1)\n",
    "        \n",
    "    output = pipeline(\n",
    "        prompt_embeds=embedding,\n",
    "        guidance_scale=0.0,\n",
    "        num_inference_steps=40,\n",
    "        output_type=\"pil\"\n",
    "    ).images\n",
    "\n",
    "    for i in range(len(output)):\n",
    "        outs.append({\n",
    "            'original': transforms.ToPILImage()(image[i]),\n",
    "            'generated': output[i]\n",
    "        })\n",
    "    \n",
    "    if len(outs) >= 40:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize original and generated side by side\n",
    "import numpy as np\n",
    "if MODE != \"T2I\":\n",
    "    fig, axs = plt.subplots(2, 10, figsize=(50, 10), dpi=300)\n",
    "    fig.suptitle(\"Original and Generated Images, Mode: {}\".format(MODE), fontsize=20)\n",
    "\n",
    "    for i in range(10):\n",
    "        axs[0, i].imshow(outs[i+30]['original']) \n",
    "        axs[0, i].axis('off')\n",
    "        axs[0, i].set_title(\"Original\")\n",
    "\n",
    "        axs[1, i].imshow(outs[i+30]['generated'])\n",
    "        axs[1, i].axis('off')\n",
    "        axs[1, i].set_title(\"Generated\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "else:\n",
    "    fig, axs = plt.subplots(2, 10, figsize=(50, 10), dpi=300)\n",
    "    fig.suptitle(\"Original and Generated Images, Mode: {}\\n Prompt: {}\".format(MODE, text[0]), fontsize=20)\n",
    "\n",
    "    for i in range(10):  \n",
    "        axs[0, i].imshow(outs[i]['generated'])\n",
    "        axs[0, i].axis('off')\n",
    "        axs[0, i].set_title(\"Generated\")\n",
    "\n",
    "        axs[1, i].imshow(outs[i + 10]['generated'])\n",
    "        axs[1, i].axis('off')\n",
    "        axs[1, i].set_title(\"Generated\")\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 5, figsize=(10, 10), dpi=100)\n",
    "fig.suptitle(\"Training Images\", fontsize=20)\n",
    "\n",
    "for i in range(25):\n",
    "    axs[i // 5, i % 5].imshow(outs[i]['original'])\n",
    "    axs[i // 5, i % 5].axis('off')\n",
    "    axs[i // 5, i % 5].set_title(\"image {}\".format(i))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "path",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
