{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "from utils.dataset_loader import CustomDatasetFromSlide\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.latent_extractor import LatentExtractor, TextEmbeddingExtractor, ImageEmbeddingExtractor\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_base_name = \"stable-diffusion-v1-5/stable-diffusion-v1-5\"\n",
    "text_encoder_base_name = \"openai/clip-vit-large-patch14\"\n",
    "image_encoder_base_name = \"openai/clip-vit-large-patch14\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"latent_files\"):\n",
    "    os.makedirs(\"latent_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "logging.info(\"Transform: {}\".format(transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"I2I\"\n",
    "\n",
    "latent_extractor = LatentExtractor(vae_name=vae_base_name, device=device, transform=None)\n",
    "\n",
    "if MODE == \"T2I\":\n",
    "    save_path = \"./latent_files/dataset_with_latents_t2i.pkl\"\n",
    "    text_embedding_extractor = TextEmbeddingExtractor(text_encoder_name=text_encoder_base_name, device=device)\n",
    "\n",
    "elif MODE == \"E2I\":\n",
    "    save_path = \"./latent_files/dataset_with_latents_e2i.pkl\"\n",
    "\n",
    "else:\n",
    "    save_path = \"./latent_files/dataset_with_latents_i2i.pkl\"\n",
    "    image_embedding_extractor = ImageEmbeddingExtractor(img_encoder_name=image_encoder_base_name, device=device)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('logs'):\n",
    "    os.makedirs('logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name =\"latent_extractor\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', \n",
    "                    filename=f'logs/{log_name}.log')\n",
    "\n",
    "logging.info(f\"Device: {device}\")\n",
    "logging.info(f\"Log file: {log_name}\")\n",
    "logging.info(f\"Save path: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Cilem/mixed-histopathology-512\")\n",
    "train_dset = dataset[\"train\"]\n",
    "train_dataset = CustomDatasetFromSlide(dataset=train_dset, \n",
    "                                       slide_dir=\"/home/cilem/Lfstorage/wsis\", \n",
    "                                       transform=transform)\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "dataset_with_latents = []\n",
    "\n",
    "for i, data in enumerate(tqdm(dataloader, desc=\"Processing dataset\")):\n",
    "\n",
    "    image = data[\"image\"].to(device)\n",
    "    google_embedding_vector = data[\"embedding\"]\n",
    "    organ = data[\"organ\"]\n",
    "\n",
    "    latent = latent_extractor.extract_latent(image=image)\n",
    "    \n",
    "    if MODE == \"T2I\":\n",
    "        text = [f\"histopathology image of {organ[j]}\" for j in range(len(organ))]\n",
    "        embedding = text_embedding_extractor.extract_text_embedding(text=text)\n",
    "    \n",
    "    elif MODE == \"E2I\":\n",
    "        embedding = google_embedding_vector\n",
    "        \n",
    "    else:\n",
    "        embedding = image_embedding_extractor.extract_image_embedding(image=image)\n",
    "\n",
    "    for j in range(len(latent)):\n",
    "        dataset_with_latents.append({\"latent\": latent[j], \n",
    "                                     \"embedding_vector\": embedding[j]})\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(dataset_with_latents, f)\n",
    "\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump(dataset_with_latents, f)\n",
    "\n",
    "print(\"Dataset with latents saved to {}\".format(save_path))\n",
    "print(\"Dataset size: {}\".format(len(dataset_with_latents)))\n",
    "      \n",
    "logging.info(\"Dataset with latents saved to {}\".format(save_path))\n",
    "logging.info(\"Dataset size: {}\".format(len(dataset_with_latents)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "path",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
